dist: xenial
language: python
python: 3.6.6
cache:
  directories:
    - $HOME/.ivy2
    - $HOME/spark
    - $HOME/.cache/pip
    - $HOME/.pip-cache
    - $HOME/.sbt/launchers
jdk:
  - oraclejdk8
sudo: false
install:
  # Download spark 2.3.3
  - "[ -f spark ] || mkdir spark && cd spark && axel http://archive.apache.org/dist/spark/spark-2.3.3/spark-2.3.3-bin-hadoop2.7.tgz && cd .."
  - "tar -xf ./spark/spark-2.3.3-bin-hadoop2.7.tgz"
  - "export SPARK_HOME=`pwd`/spark-2.3.3-bin-hadoop2.7"
  - echo "spark.yarn.jars=$SPARK_HOME/jars/*.jar" > $SPARK_HOME/conf/spark-defaults.conf
  # Install Python deps.
  - pip install -r requirements_dev.txt
  - pip install -e .
script:
  - make test
after_success:
  - coveralls
